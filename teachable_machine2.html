<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title> WebSocket通信 </title>
    <script type="text/javascript">
        // Web Socketオブジェクト生成
        var webSocket = new WebSocket("ws://127.0.0.1:30000");
        webSocket.onopen = function() {
           document.getElementById('show').innerHTML += "接続しました。" + "<br/>";
            // onmessageリスナー
            webSocket.onmessage = function(event) {
                // 取得＆表示
                document.getElementById('show').innerHTML += event.data + "<br/>";
            }
        };
        var sendMsg = function(val) {
            var inputElement = document.getElementById('msg');
            // 送信
            webSocket.send(inputElement.value);
            // クリア
            inputElement.value = "";
        }
    </script>
</head>

<body>
    <div style="width:500px;height:200px;overflow-y:auto;border:1px solid #333;" id="show"></div>
    <input type="text" size="80" id="msg" name="msg" />
    <input type="button" value="送信" onclick="sendMsg();" />

<!-- ここからteachablemachine -->

    <div>Teachable Machine Pose Model</div>
    <button type="button" onclick="init()">Start</button>
    <div><canvas id="canvas"></canvas></div>
    <div id="label-container"></div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
    <script type="text/javascript">
          // More API functions here:
          // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose
          // the link to your model provided by Teachable Machine export panel
          // const URL = "https://teachablemachine.withgoogle.com/models/gRWcvQapv/";
          const URL = "https://teachablemachine.withgoogle.com/models/A7O1o4hJ1/";
          let model, webcam, ctx, labelContainer, maxPredictions;

          var data=[]
          // var data=""
          var fly=false

          async function init() {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
            // Note: the pose library adds a tmPose object to your window (window.tmPose)
            //モデルとメタデータをロードする
            //ファイルピッカーからのファイルをサポートするために、APIのtmImage.loadFromFiles()を参照してください。
            //注意: pose ライブラリは、tmPose オブジェクトをウィンドウに追加します (window.tmPose)
            model = await tmPose.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();//モデルの数

            // Convenience function to setup a webcam
            // ウェブカメラをセットアップするための便利な機能
            const size = 400;
            const flip = true; // whether to flip the webcam ウェブカメラを反転させるかどうか
            webcam = new tmPose.Webcam(size, size, flip); // width, height, flip
            await webcam.setup(); // request access to the webcam ウェブカメラへのアクセスを要求する
            await webcam.play();
            window.requestAnimationFrame(loop);

            // append/get elements to the DOM
            // DOMに要素を追加/取得する
            const canvas = document.getElementById("canvas");
            canvas.width = size;
            canvas.height = size;
            ctx = canvas.getContext("2d");
            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) { // and class labels
              labelContainer.appendChild(document.createElement("div"));
            }

            //--------タイマー処理----------------
            var manager = async function () {
              if (data !==[]) {
                var n = data.length-1
                var x = 0
                if(data[n]=="RIGHT" && fly){
                  webSocket.send("RIGHT")
                }else if(data[n]=="LEFT" && fly){
                  webSocket.send("LEFT")
                }else{
                  for (var i = 0; i < data.length-1; i++) {
                    // data[i]
                    if((data[i]==="UP"&&data[i+1]==="DOWN")
                    ||(data[i]==="DOWN"&&data[i+1]==="UP")){
                      x++
                    }
                  }
                  if(x >= 2 && !fly){
                    fly=true
                    webSocket.send("FLY")
                  }else if(fly){
                    fly=false
                    webSocket.send("LAND")
                  }
                }
                // webSocket.send()
                data = [];
              }
            }
            setInterval(manager, 3000)
            //-----------------------------------
            
          }

          async function loop(timestamp) {
             webcam.update(); // update the webcam frame
             await predict();
             window.requestAnimationFrame(loop);
          }

          async function predict() {
             // Prediction #1: run input through posenet
             // estimatePose can take in an image, video or canvas html element
             // 予測1：posenetで入力を実行する推定ポーズは、画像、ビデオ、またはキャンバスのhtml要素を取り込むことができます。
             const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
             // Prediction 2: run input through teachable machine classification model
             // 予測2：ティーチングマシン分類モデルによる入力の実行
             const prediction = await model.predict(posenetOutput);

             for (let i = 0; i < maxPredictions; i++) {
                 const classPrediction =
                     prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                 labelContainer.childNodes[i].innerHTML = classPrediction;

                 if(prediction[i].className=="UP"){
                   if(prediction[i].probability.toFixed(2)=="1.00"){
                     data.push("UP")
                     // data="UP"
                     // webSocket.send("UP")
                   }
                 }
                 if(prediction[i].className=="DOWN"){
                   if(prediction[i].probability.toFixed(2)=="1.00"){
                     data.push("DOWN")
                     // data="DOWN"
                     // webSocket.send("DOWN")
                   }
                 }
                 if(prediction[i].className=="RIGHT"){
                   if(prediction[i].probability.toFixed(2)=="1.00"){
                     data.push("RIGHT")
                     // data="RIGHT"
                     // webSocket.send("RIGHT")
                   }
                 }
                 if(prediction[i].className=="LEFT"){
                   if(prediction[i].probability.toFixed(2)=="1.00"){
                     data.push("LEFT")
                     // data="LEFT"
                     // webSocket.send("LEFT")
                   }
                 }


             }

             // finally draw the poses
             drawPose(pose);
          }



          function drawPose(pose) {
             if (webcam.canvas) {
                 ctx.drawImage(webcam.canvas, 0, 0);
                 // draw the keypoints and skeleton
                 if (pose) {
                     const minPartConfidence = 0.5;
                     tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
                     tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
                 }
             }
          }

    </script>
</body>

</html>
